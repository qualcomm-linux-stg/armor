
name: "Print Event SHAs"
description: "Run ARMOR tool"
author: "LinuxIntegration"
branding:
  icon: "align-left"
  color: "blue"

inputs:
  event-name:
    description: "github.event_name from the caller"
    required: true
  head-sha:
    description: "Head SHA for the event (PR head or push after)"
    required: true
  base-sha:
    description: "Base SHA for the event (PR base or push before)"
    required: false
    default: ""
  ref:
    description: "Ref associated with the event"
    required: false
    default: ""
  repo:
    description: "owner/repo of the caller"
    required: false
    default: ""
  repo-token:
    description: "Token for GitHub API calls"
    required: true
  branch-name:
    description: "Branch name for the event"
    required: true

runs:
  using: "composite"
  steps:
    - name: Checkout base commit
      uses: actions/checkout@v4
      with:
        ref: ${{ inputs.base-sha }}
        path: base
        fetch-depth: 0

    - name: Checkout head commit
      uses: actions/checkout@v4
      with:
        ref: ${{ inputs.head-sha }}
        path: head
        fetch-depth: 0

    - name: Echo paths and SHAs
      shell: bash
      run: |
        echo "Event       : ${{ inputs.event-name }}"
        echo "Base SHA    : ${{ inputs.base-sha }}"
        echo "Head SHA    : ${{ inputs.head-sha }}"
        echo "github-base path : $GITHUB_WORKSPACE/base"
        echo "github-head path : $GITHUB_WORKSPACE/head"


    - name: Verify gcc and Docker installation
      shell: bash
      run: |
        set -e
        gcc --version || { echo "gcc missing"; exit 1; }
        docker --version || { echo "docker missing"; exit 1; }

    - name: Build docker image (use action directory as context)
      shell: bash
      run: |
        set -e
        docker build -t armor_tool:latest -f "${{ github.action_path }}/Dockerfile" "${{ github.action_path }}"

    - name: Install yq
      shell: bash
      run: |
        set -e
        if ! command -v yq >/dev/null 2>&1; then
          sudo apt-get update -y
          sudo apt-get install -y jq
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/download/v4.44.3/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
        fi

    - name: Get changed files
      id: changed-files
      shell: bash
      run: |
        set -e
        # Diff directly using the two trees
        git --git-dir="$GITHUB_WORKSPACE/head/.git" --work-tree="$GITHUB_WORKSPACE/head" diff --name-only ${{ inputs.base-sha }} ${{ inputs.head-sha }} > "$GITHUB_WORKSPACE/changed_files.txt" || true
        echo "Changed files:"
        cat "$GITHUB_WORKSPACE/changed_files.txt" || true

    
    - name: Parse YAML for headers (dirs/globs allowed) and expand to file list
      id: parse-yaml
      shell: bash
      run: |
        set -euo pipefail
        YAML_FILE="$GITHUB_WORKSPACE/public_headers/armor_config.yaml"
        CURRENT_BRANCH="${{ inputs.branch-name }}"
        BASE_PATH="$GITHUB_WORKSPACE/base"
        HEAD_PATH="$GITHUB_WORKSPACE/head"

        # Ensure YAML exists
        [[ -f "$YAML_FILE" ]] || { echo "YAML file not found at $YAML_FILE"; exit 1; }

        echo "Parsing $YAML_FILE for branch: $CURRENT_BRANCH"

        ########################################
        # Common helpers (reusable)
        ########################################

        # 1) Extract patterns for a given mode into a target file (deduped)
        # usage: extract_patterns "blocking" "$OUT_FILE"
        extract_patterns() {
          local mode="$1"
          local out="$2"

          : > "$out"
          # Pull headers[]; tolerate missing keys
          yq ".branches.${CURRENT_BRANCH}.modes.${mode}.headers[]" "$YAML_FILE" >> "$out" || true
          # De-duplicate
          sort -u -o "$out" "$out"

          echo "Patterns (${mode}):"
          cat "$out" || true
        }

        # 2) Expand patterns (base/head), normalize to repo-relative paths, produce final list
        # usage: expand_and_normalize "$PATTERNS_FILE" "$BASE_OUT" "$HEAD_OUT" "$FINAL_OUT"
        expand_and_normalize() {
          local patterns_file="$1"
          local expanded_base="$2"
          local expanded_head="$3"
          local final_out="$4"

          : > "$expanded_base"
          : > "$expanded_head"
          : > "$final_out"

          while IFS= read -r patt; do
            [[ -z "${patt// }" ]] && continue
            expand_pattern "$BASE_PATH" "$patt" "$expanded_base"
            expand_pattern "$HEAD_PATH" "$patt" "$expanded_head"
          done < "$patterns_file"

          # Convert absolute -> repo-relative
          sed -E "s|^${BASE_PATH}/||" "$expanded_base" > "${final_out}.tmp1" || true
          sed -E "s|^${HEAD_PATH}/||" "$expanded_head" >> "${final_out}.tmp1" || true

          # Keep only .h/.hpp, de-duplicate
          grep -E '\.(h|hpp)$' "${final_out}.tmp1" | sort -u > "$final_out" || true
          rm -f "${final_out}.tmp1"

          echo "Resolved headers → $final_out"
          cat "$final_out" || true
        }

        ########################################
        # Existing expand_pattern: keep your version
        # (Copied here for completeness; if defined earlier, skip redefining)
        ########################################
        expand_pattern() {
          local root="$1"
          local patt="$2"
          local out="$3"

          # Normalize leading './'
          case "$patt" in
            ./*) patt="${patt#./}" ;;
          esac

          # Trailing '/' means a directory → find *.h *.hpp recursively
          if [[ "$patt" == */ ]]; then
            local dir="${patt%/}"
            if [[ -d "$root/$dir" ]]; then
              find "$root/$dir" -type f \( -name "*.h" -o -name "*.hpp" \) -print >> "$out"
            fi
            return
          fi

          if [[ -d "$root/$patt" ]]; then
              find "$root/$patt" -type f \( -name "*.h" -o -name "*.hpp" \) -print >> "$out"
              return
          fi


          # If pattern contains glob characters, expand via 'find'
          if [[ "$patt" == *"*"* || "$patt" == *"?"* || "$patt" == *"["*"]"* ]]; then
            local dir_part
            dir_part="$(dirname "$patt")"
            local base_part
            base_part="$(basename "$patt")"
            local search_dir="$root"
            [[ "$dir_part" != "." ]] && search_dir="$root/$dir_part"

            if [[ -d "$search_dir" ]]; then
              case "$base_part" in
                "**.h"|"**/*.h")   find "$search_dir" -type f -name "*.h"   -print >> "$out" ;;
                "**.hpp"|"**/*.hpp") find "$search_dir" -type f -name "*.hpp" -print >> "$out" ;;
                *)                 find "$search_dir" -type f -name "$base_part" -print >> "$out" ;;
              esac
            fi
            return
          fi

          # Otherwise treat as an explicit file path relative to root
          [[ -f "$root/$patt" ]] && echo "$root/$patt" >> "$out"
        }

        ########################################
        # DRY orchestration over modes
        ########################################

        # Define per-mode files in one place
        declare -A PATTERNS_FILE
        declare -A EXP_BASE
        declare -A EXP_HEAD
        declare -A FINAL_OUT

        PATTERNS_FILE["blocking"]="$GITHUB_WORKSPACE/blocking_patterns.txt"
        PATTERNS_FILE["non-blocking"]="$GITHUB_WORKSPACE/nonblocking_patterns.txt"

        EXP_BASE["blocking"]="$GITHUB_WORKSPACE/expanded_blocking_base.txt"
        EXP_HEAD["blocking"]="$GITHUB_WORKSPACE/expanded_blocking_head.txt"
        FINAL_OUT["blocking"]="$GITHUB_WORKSPACE/blocking_headers_final.txt"

        EXP_BASE["non-blocking"]="$GITHUB_WORKSPACE/expanded_nonblocking_base.txt"
        EXP_HEAD["non-blocking"]="$GITHUB_WORKSPACE/expanded_nonblocking_head.txt"
        FINAL_OUT["non-blocking"]="$GITHUB_WORKSPACE/nonblocking_headers_final.txt"

        for mode in "blocking" "non-blocking"; do
          extract_patterns "$mode" "${PATTERNS_FILE[$mode]}"
          expand_and_normalize \
            "${PATTERNS_FILE[$mode]}" \
            "${EXP_BASE[$mode]}" \
            "${EXP_HEAD[$mode]}" \
            "${FINAL_OUT[$mode]}"
        done

        # Preserve the previous combined behavior if needed:
        COMBINED_HEADERS="$GITHUB_WORKSPACE/headers.txt"
        cat "${FINAL_OUT["blocking"]}" "${FINAL_OUT["non-blocking"]}" | sort -u > "$COMBINED_HEADERS" || true
        echo "Combined headers → $COMBINED_HEADERS"
        cat "$COMBINED_HEADERS" || true

    - name: Find intersection of changed files and headers
      id: intersection
      shell: bash
      run: |
        set -e
        INTERSECT=$(grep -Fxf "$GITHUB_WORKSPACE/headers.txt" "$GITHUB_WORKSPACE/changed_files.txt" || true)
        echo "$INTERSECT" > "$GITHUB_WORKSPACE/updated_headers_PR.txt"
        if [[ -n "$INTERSECT" ]]; then
          echo "Intersection found:"
          cat "$GITHUB_WORKSPACE/updated_headers_PR.txt"
          echo "has-intersection=true" >> "$GITHUB_OUTPUT"
        else
          echo "No intersection found."
          : > "$GITHUB_WORKSPACE/updated_headers_PR.txt"
          echo "has-intersection=false" >> "$GITHUB_OUTPUT"
        fi

    - name: Build ARMOR tool inside container
      shell: bash
      run: |
        set -euo pipefail
        ACTION_DIR="${{ github.action_path }}"
        docker run -i --rm \
          --user $(id -u):$(id -g) \
          -v "$ACTION_DIR":"$ACTION_DIR" \
          -e ACTION_DIR="$ACTION_DIR" \
          -w "$ACTION_DIR" \
          armor_tool:latest bash -c '
            set -euo pipefail
            chmod +x ./api_compat_check.sh
            ./api_compat_check.sh --package
            echo "$ACTION_DIR/build/armor" > "$ACTION_DIR/.armor_bins_path"
          '

    - name: Run ARMOR per header (collect outputs)
      if: steps.intersection.outputs.has-intersection == 'true'
      id: run-armor
      shell: bash
      env:
        REPORT_FORMAT: "json"
        LOG_LEVEL: "INFO"
        DUMP_AST_DIFF: "true"
      run: |
        set -e
        BASE_PATH="$GITHUB_WORKSPACE/base"
        HEAD_PATH="$GITHUB_WORKSPACE/head"
        INTERSECTION_HEADERS_PATH="$GITHUB_WORKSPACE/updated_headers_PR.txt"
        ARMOR_BINS_PATH="$(cat "${{ github.action_path }}/.armor_bins_path")"

        chmod +x "${{ github.action_path }}/action_script/run_armor.sh"
        "${{ github.action_path }}/action_script/run_armor.sh" "$BASE_PATH" "$HEAD_PATH" "$INTERSECTION_HEADERS_PATH" "$ARMOR_BINS_PATH"

        OUT_ROOT="$(cat "$GITHUB_WORKSPACE/.armor_out_root")"
        echo "out-root=$OUT_ROOT" >> "$GITHUB_OUTPUT"

    - name: Upload updated_headers_PR artifact
      if: steps.intersection.outputs.has-intersection == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: updated_headers_PR
        path: ${{ github.workspace }}/updated_headers_PR.txt

    - name: Upload all armor outputs (artifact)
      if: steps.intersection.outputs.has-intersection == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: armor-output-${{ inputs.head-sha }}
        path: ${{ steps.run-armor.outputs.out-root }}
        if-no-files-found: warn

    - name: Compute compatibility status
      id: compatibility_status
      shell: bash
      run: |
        set -e
        # Expect your run_armor.sh to set status file or output; adjust as needed
        STATUS_FILE="$GITHUB_WORKSPACE/.armor_status"
        if [[ -f "$STATUS_FILE" ]]; then
          STATUS="$(cat "$STATUS_FILE")"
        else
          STATUS="success"
        fi
        echo "Overall status: $STATUS"
        echo "res=$STATUS" >> "$GITHUB_OUTPUT"

    - name: Post PR comment with ARMOR summary
      if: github.event_name == 'pull_request' || github.event_name == 'pull_request_target'
      shell: bash
      run: |
        set -euo pipefail

        # Inputs and common context
        repo="${{ inputs.repo }}"
        pr="${{ github.event.pull_request.number }}"
        token="${{ inputs.repo-token }}"
        workflow_url="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
        artifacts="${workflow_url}#artifacts"
        out_root="${{ steps.run-armor.outputs.out-root }}"
        summary_path="${out_root}/compact_summary.json"
        incompatible_path="${out_root}/metadata.txt"
        status="${{ steps.compatibility_status.outputs.res }}"

        body="$(cat <<'EOF'
        ### ARMOR Check Result

        **Status:** `__STATUS__`

        Please check __ARTIFACTS__ for details.
        EOF
        )"
        # Substitute tokens
        body="${body/__STATUS__/${status}}"
        body="${body/__ARTIFACTS__/${artifacts}}"

        # Append incompatible headers section if present and non-empty
        if [[ -f "$summary_path" ]]; then
          if [[ -f "$incompatible_path" && -s "$incompatible_path" ]]; then
            failed_headers=""
            # Build a clean markdown list with no leading spaces
            while IFS= read -r line; do
              # Skip blank lines
              [[ -z "$line" ]] && continue
              failed_headers+=$'- '"$line"$'\n'
            done < "$incompatible_path"

            body+=$'\n\n**Backward Incompatible Headers:**\n'
            body+="${failed_headers}"
          fi
        fi

        # Show what we'll post (use printf to preserve newlines)
        printf '%s\n' "$body"

        # Post the comment to the PR
        curl -L \
          -X POST \
          -H "Accept: application/vnd.github+json" \
          -H "Authorization: Bearer ${{ inputs.repo-token }}" \
          -H "X-GitHub-Api-Version: 2022-11-28" \
          "https://api.github.com/repos/${repo}/issues/${pr}/comments" \
          -d "$(jq -n --arg body "$body" '{body: $body}')"

    - name: Fail if incompatible changes detected
      if: steps.intersection.outputs.has-intersection == 'true'
      shell: bash
      run: |
        set -euo pipefail
        status="${{ steps.run-armor.outputs.status }}"
        if [[ "$status" == "failure" ]]; then
          echo "::error ::ARMOR detected backward incompatible changes. Failing the check."
          exit 1
        else
          echo "ARMOR check passed (status: $status)."
        fi
